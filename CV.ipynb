{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:23:33.241570Z",
     "start_time": "2024-11-19T20:23:29.296544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "46e07ecff1595fd1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732047810.332234   25429 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732047810.376916   25429 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:23:34.291926Z",
     "start_time": "2024-11-19T20:23:33.840341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ],
   "id": "6238ca41c44b955c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:23:34.304264Z",
     "start_time": "2024-11-19T20:23:34.298077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_model(_model, path):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "def generate_cpp(path):\n",
    "    var_names = (\n",
    "        path.replace(\"/\", \"_\").replace(\".\", \"_\"),\n",
    "        path.replace(\"/\", \"_\").replace(\".\", \"_\") + \"_len\"\n",
    "    )\n",
    "    cpp_path = path.replace(\".tflite\", \".cpp\")\n",
    "    os.system(f'xxd -i {path} > {cpp_path}')\n",
    "\n",
    "    with open(cpp_path, 'r') as f:\n",
    "        cpp_text = f.read()\n",
    "\n",
    "    h_path = cpp_path.replace(\".cpp\", \".h\")\n",
    "    with open(h_path, 'w') as f:\n",
    "        f.write(f\"extern unsigned char {var_names[0]}[];\\n\")\n",
    "        f.write(f\"extern unsigned int {var_names[1]};\")\n",
    "\n",
    "    h_name = h_path.split(\"/\")[-1]\n",
    "    with open(cpp_path, \"w\") as f:\n",
    "        f.write(f'#include \"{h_name}\"\\n\\n' + cpp_text)\n",
    "\n",
    "def get_evaluation(model, history, epochs, x_test, y_test, path):\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    train_acc = history['sparse_categorical_accuracy']\n",
    "    val_acc = history['val_sparse_categorical_accuracy']\n",
    "\n",
    "    figure = plt.figure()\n",
    "    plt.plot(range(1, 1 + epochs), train_loss, label='train loss')\n",
    "    plt.plot(range(1, 1 + epochs), val_loss, label='validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(path + \"/loss.png\")\n",
    "    plt.close(figure)\n",
    "\n",
    "    figure = plt.figure()\n",
    "    plt.plot(range(1, 1 + epochs), train_acc, label='train acc')\n",
    "    plt.plot(range(1, 1 + epochs), val_acc, label='validation acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(path + \"/accuracy.png\")\n",
    "    plt.close(figure)\n",
    "\n",
    "    print(model.evaluate(x_test, y_test))"
   ],
   "id": "ddc8ea2d23ef7168",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MNIST Dataset",
   "id": "9416d74f23a629d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:38:24.381669Z",
     "start_time": "2024-11-19T16:38:24.219025Z"
    }
   },
   "cell_type": "code",
   "source": "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()",
   "id": "9586926c6f029160",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:38:24.576053Z",
     "start_time": "2024-11-19T16:38:24.490464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ],
   "id": "f3c76aa567c008a5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:56:15.977160Z",
     "start_time": "2024-11-19T16:56:15.975336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 3\n",
    "lr = 0.001"
   ],
   "id": "db39f0e0fe1bc042",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:55:51.036003Z",
     "start_time": "2024-11-19T16:55:51.034233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter_n = 10\n",
    "filter_start = 1\n",
    "filter_size_n = 3\n",
    "\n",
    "conv_x_train = x_train.reshape((50000, 28, 28, 1))\n",
    "conv_x_val = x_val.reshape((10000, 28, 28, 1))\n",
    "conv_x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "conv_y_train = y_train\n",
    "conv_y_val = y_val\n",
    "conv_y_test = y_test\n",
    "\n",
    "for i in range(filter_start, filter_start + filter_n):\n",
    "    for j in range(1, 1 + filter_size_n):\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(i, kernel_size=(j, j), activation='relu', input_shape=(28, 28, 1)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            conv_x_train,\n",
    "            conv_y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(conv_x_val, conv_y_val)\n",
    "        )\n",
    "        history = history.history\n",
    "\n",
    "        path = f\"models/conv{i}_{j}x{j}_dense\"\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        get_evaluation(model, history, epochs, conv_x_test, conv_y_test, path)\n",
    "\n",
    "        path += f\"/conv{i}_{j}x{j}_dense.tflite\"\n",
    "        convert_model(model, path)\n",
    "        generate_cpp(path)"
   ],
   "id": "82e1855789f4f7d5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:04:01.917034Z",
     "start_time": "2024-11-19T17:03:13.658336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10, 100, 10):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(i, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val, y_val)\n",
    "    )\n",
    "    history = history.history\n",
    "\n",
    "    path = f\"models/flatten_dense{i}_dense\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    get_evaluation(model, history, epochs, x_test, y_test, path)\n",
    "\n",
    "    path += f\"/flatten_dense{i}_dense.tflite\"\n",
    "    convert_model(model, path)\n",
    "    generate_cpp(path)"
   ],
   "id": "608f5edf2fd60196",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 977us/step - loss: 0.9540 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.3204 - val_sparse_categorical_accuracy: 0.9110\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 663us/step - loss: 0.3291 - sparse_categorical_accuracy: 0.9053 - val_loss: 0.2806 - val_sparse_categorical_accuracy: 0.9221\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 765us/step - loss: 0.2917 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.9286\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 467us/step - loss: 0.3104 - sparse_categorical_accuracy: 0.9120\n",
      "[0.27602845430374146, 0.9218999743461609]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcjmopdn8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcjmopdn8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpcjmopdn8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_36')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877568867216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877568868176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877568867600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877568867792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035798.452066    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035798.452076    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 898us/step - loss: 0.7161 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9314\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 541us/step - loss: 0.2477 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.2051 - val_sparse_categorical_accuracy: 0.9416\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 569us/step - loss: 0.2041 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.1853 - val_sparse_categorical_accuracy: 0.9490\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434us/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9379\n",
      "[0.19138400256633759, 0.9463000297546387]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyor8tj9q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyor8tj9q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpyor8tj9q'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_40')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877567386320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877567386704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877568866832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877568866448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035802.866013    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035802.866025    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 914us/step - loss: 0.6424 - sparse_categorical_accuracy: 0.8158 - val_loss: 0.2236 - val_sparse_categorical_accuracy: 0.9354\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 971us/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.1725 - val_sparse_categorical_accuracy: 0.9496\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 562us/step - loss: 0.1762 - sparse_categorical_accuracy: 0.9496 - val_loss: 0.1556 - val_sparse_categorical_accuracy: 0.9529\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - loss: 0.1766 - sparse_categorical_accuracy: 0.9491\n",
      "[0.16127485036849976, 0.953000009059906]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpohalm0bl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpohalm0bl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpohalm0bl'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_44')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877835266064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132879444146128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132879444139600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132879900053328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035807.833270    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035807.833279    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 975us/step - loss: 0.5788 - sparse_categorical_accuracy: 0.8401 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9395\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 757us/step - loss: 0.1936 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 0.9556\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 620us/step - loss: 0.1466 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.1359 - val_sparse_categorical_accuracy: 0.9605\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 377us/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9523\n",
      "[0.14068761467933655, 0.9577999711036682]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnswfvce5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnswfvce5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpnswfvce5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_48')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877570037648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877840310800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877570043984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877840314256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035812.822749    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035812.822759    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - loss: 0.5933 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.1923 - val_sparse_categorical_accuracy: 0.9473\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 839us/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9452 - val_loss: 0.1468 - val_sparse_categorical_accuracy: 0.9599\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 760us/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9613\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - loss: 0.1573 - sparse_categorical_accuracy: 0.9527\n",
      "[0.13701650500297546, 0.9602000117301941]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprcvi757i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprcvi757i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmprcvi757i'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_52')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877433787536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877567382672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877567389392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877567391696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035818.509354    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035818.509366    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - loss: 0.5716 - sparse_categorical_accuracy: 0.8398 - val_loss: 0.1832 - val_sparse_categorical_accuracy: 0.9495\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 874us/step - loss: 0.1817 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9581\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.1221 - val_sparse_categorical_accuracy: 0.9651\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9566\n",
      "[0.12244392186403275, 0.9632999897003174]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0rpqcytr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0rpqcytr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp0rpqcytr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_56')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877433785232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877433792720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877433782544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877433796752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035824.947480    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035824.947490    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - loss: 0.5242 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9501\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9651\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 629us/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9665\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 0.1312 - sparse_categorical_accuracy: 0.9608\n",
      "[0.11257892847061157, 0.9660000205039978]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp93vhez0r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp93vhez0r/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp93vhez0r'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_60')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877302375120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302368592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302371664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302379536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035830.711220    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035830.711230    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 991us/step - loss: 0.5115 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9557\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 629us/step - loss: 0.1548 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 901us/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9694\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9658\n",
      "[0.1038479134440422, 0.9708999991416931]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2vnxh_3e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2vnxh_3e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp2vnxh_3e'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_64')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877302379728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302377232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302373200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877302376464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035836.003343    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035836.003352    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - loss: 0.4942 - sparse_categorical_accuracy: 0.8627 - val_loss: 0.1754 - val_sparse_categorical_accuracy: 0.9526\n",
      "Epoch 2/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 606us/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1211 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 3/3\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 654us/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9699\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374us/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9674\n",
      "[0.10412027686834335, 0.9700000286102295]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzn21ndtg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzn21ndtg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpzn21ndtg'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor_68')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877297002896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877296998288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877297005968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877297006736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732035841.817275    3792 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732035841.817288    3792 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:54:43.247418Z",
     "start_time": "2024-11-19T16:54:43.244313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_image_code(x):\n",
    "    with open(\"init_input.h\", \"w\") as f:\n",
    "        f.write('#include \"tensorflow/lite/c/common.h\" \\n\\n')\n",
    "        f.write(\"void init_input(TfLiteTensor *input);\")\n",
    "\n",
    "    with open(\"init_input.cpp\", \"w\") as f:\n",
    "        f.write('#include \"init_input.h\"\\n')\n",
    "        f.write('#include \"tensorflow/lite/c/common.h\" \\n\\n')\n",
    "        f.write(\"void init_input(TfLiteTensor *input) {\\n\")\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                f.write(f\"\\tinput->data.f[{i*x.shape[0] + j}] = {x[i][j]};\\n\")\n",
    "        f.write(\"}\\n\")"
   ],
   "id": "7e0f68bb40ba7977",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:54:43.578207Z",
     "start_time": "2024-11-19T16:54:43.575133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = y_test[0]\n",
    "x = x_test[0].reshape((28, 28))\n",
    "print(y)"
   ],
   "id": "a5b12f24e0ed0e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:54:44.298755Z",
     "start_time": "2024-11-19T16:54:44.295719Z"
    }
   },
   "cell_type": "code",
   "source": "get_image_code(x)",
   "id": "cf66f10d3c4a8023",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:16:25.568548Z",
     "start_time": "2024-11-19T17:16:25.513743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(x)\n",
    "plt.show()"
   ],
   "id": "a83b77dc256a9de8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MPII Human Pose Dataset",
   "id": "7df1ba4bf350b722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:23:45.873564Z",
     "start_time": "2024-11-19T20:23:45.812550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import scipy.io as spio\n",
    "from tqdm.auto import tqdm"
   ],
   "id": "85d6c69ac8f20edd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:24:37.005362Z",
     "start_time": "2024-11-19T20:23:46.590126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_url = \"https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz\"\n",
    "archive = keras.utils.get_file(origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(archive)"
   ],
   "id": "2cc8c25e6ab36064",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:24:39.240572Z",
     "start_time": "2024-11-19T20:24:39.117460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_list = list(data_dir.glob(\"*/*.jpg\"))\n",
    "n = len(path_list)"
   ],
   "id": "2bdc684066ec0d64",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:24:43.134630Z",
     "start_time": "2024-11-19T20:24:39.910292Z"
    }
   },
   "cell_type": "code",
   "source": "mpii_mat = spio.loadmat(\"mpii_human_pose_v1_u12_1.mat\")",
   "id": "c04a46fe72a2a137",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:24:44.680674Z",
     "start_time": "2024-11-19T20:24:44.677648Z"
    }
   },
   "cell_type": "code",
   "source": "mpii_metadata = mpii_mat.get(\"RELEASE\")[0][0]",
   "id": "6225bb9c277a2446",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:24:45.282897Z",
     "start_time": "2024-11-19T20:24:45.280627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "annolists = mpii_metadata[\"annolist\"][0]\n",
    "acts = mpii_metadata[\"act\"]"
   ],
   "id": "43c23e0df3474232",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:28:42.148740Z",
     "start_time": "2024-11-19T20:25:07.873397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images = []\n",
    "belong_classes = []\n",
    "\n",
    "test_images = []\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    img = keras.utils.load_img(path_list[i])\n",
    "    img = tf.image.resize(img, (75, 75))\n",
    "\n",
    "    category = acts[i][0][\"cat_name\"]\n",
    "    if category.shape[0] == 0:\n",
    "        test_images.append(img)\n",
    "    else:\n",
    "        images.append(img)\n",
    "        belong_classes.append(category[0][0])"
   ],
   "id": "bf8e8cce7c41c230",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24984 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbeb71a0c27f4122b18cd0385bf07128"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:28:43.929670Z",
     "start_time": "2024-11-19T20:28:43.925422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes_count = list(set(belong_classes))\n",
    "print(classes_count)\n",
    "print(len(classes_count))\n",
    "\n",
    "class_dict = {}\n",
    "for i in range(len(classes_count)):\n",
    "    class_dict[classes_count[i]] = i\n",
    "class_dict"
   ],
   "id": "77b332bab27e237a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'w', 'h', 'b', 'm', 'd', 'v', 'o', 't', 'i', 'f', 'c', 'r', 's']\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'l': 0,\n",
       " 'w': 1,\n",
       " 'h': 2,\n",
       " 'b': 3,\n",
       " 'm': 4,\n",
       " 'd': 5,\n",
       " 'v': 6,\n",
       " 'o': 7,\n",
       " 't': 8,\n",
       " 'i': 9,\n",
       " 'f': 10,\n",
       " 'c': 11,\n",
       " 'r': 12,\n",
       " 's': 13}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:28:44.790730Z",
     "start_time": "2024-11-19T20:28:44.786096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(belong_classes)):\n",
    "    belong_classes[i] = class_dict[belong_classes[i]]"
   ],
   "id": "9fdb7d04b6747f89",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:28:45.285107Z",
     "start_time": "2024-11-19T20:28:45.279743Z"
    }
   },
   "cell_type": "code",
   "source": "belong_classes",
   "id": "6c047828a995b8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 12,\n",
       " 12,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 3,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:37:15.814394Z",
     "start_time": "2024-11-19T20:37:15.380993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np_images = np.array(images)\n",
    "np_belong_classes = np.array(belong_classes)"
   ],
   "id": "aed1666db8e8161a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:49:35.118069Z",
     "start_time": "2024-11-19T20:49:34.635356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "permutation = np.random.permutation(len(np_images))\n",
    "\n",
    "val_portion = 0.3\n",
    "train_index = int(np_images.shape[0] * val_portion)\n",
    "\n",
    "np_train_images = np_images[permutation][:train_index]\n",
    "np_val_images = np_images[permutation][train_index:]\n",
    "np_train_classes = np_belong_classes[permutation][:train_index]\n",
    "np_val_classes = np_belong_classes[permutation][train_index:]"
   ],
   "id": "8490757f8ecb8be",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:52:19.598861Z",
     "start_time": "2024-11-19T19:52:07.864179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_images = tf.convert_to_tensor(np_images, dtype=tf.float32)\n",
    "tensor_belong_classes = tf.convert_to_tensor(np_belong_classes, dtype=tf.float32)"
   ],
   "id": "50ac4724211243c9",
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tensor_images \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m tensor_belong_classes \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(np_belong_classes, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[0;32m~/.virtualenvs/CVEsp32/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.virtualenvs/CVEsp32/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    106\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    107\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:53:18.408341Z",
     "start_time": "2024-11-19T20:53:18.405975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 3\n",
    "lr = 0.05"
   ],
   "id": "8fea3e165597b198",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:53:18.925088Z",
     "start_time": "2024-11-19T20:53:18.922745Z"
    }
   },
   "cell_type": "code",
   "source": "np_images.shape",
   "id": "47aca521b235b6b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18032, 75, 75, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T21:09:16.502516Z",
     "start_time": "2024-11-19T21:04:49.171838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter_n = 10\n",
    "filter_start = 1\n",
    "filter_size_n = 5\n",
    "\n",
    "for i in range(filter_start, filter_start + filter_n):\n",
    "    for j in range(filter_start, filter_start + filter_size_n):\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(i, kernel_size=(j, j), activation='relu', input_shape=(75, 75, 3)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(14, activation='softmax'),\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.AdamW(lr),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            np_train_images,\n",
    "            np_train_classes,\n",
    "            epochs=epochs,\n",
    "            validation_data=(np_val_images, np_val_classes)\n",
    "        )\n",
    "        history = history.history\n",
    "\n",
    "        path = f\"models/mpii/mpii_conv{i}_{j}x{j}_dense14\"\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        get_evaluation(model, history, epochs, np_val_images, np_val_classes, path)\n",
    "\n",
    "        path += f\"/mpii_conv{i}_{j}x{j}_dense14.tflite\"\n",
    "        convert_model(model, path)\n",
    "        generate_cpp(path)"
   ],
   "id": "9bee19392c8f8135",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 3471.2800 - sparse_categorical_accuracy: 0.1460 - val_loss: 2.3574 - val_sparse_categorical_accuracy: 0.2028\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.3350 - sparse_categorical_accuracy: 0.1996 - val_loss: 2.3335 - val_sparse_categorical_accuracy: 0.2028\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.3293 - sparse_categorical_accuracy: 0.2017 - val_loss: 2.3222 - val_sparse_categorical_accuracy: 0.2030\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 817us/step - loss: 2.3189 - sparse_categorical_accuracy: 0.2050\n",
      "[2.322162628173828, 0.20304206013679504]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0in30vok/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0in30vok/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp0in30vok'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_225')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048046031760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048046029840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048046032144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048046035216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050293.665621   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050293.665632   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 647.9752 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.2845 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2942 - sparse_categorical_accuracy: 0.1994 - val_loss: 2.2842 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.3000 - sparse_categorical_accuracy: 0.1986 - val_loss: 2.2837 - val_sparse_categorical_accuracy: 0.2038\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 839us/step - loss: 2.2769 - sparse_categorical_accuracy: 0.2059\n",
      "[2.283679246902466, 0.20383426547050476]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7aw4hzz0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7aw4hzz0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp7aw4hzz0'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_229')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048046032720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048050216208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048050212368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048050212752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050298.937018   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050298.937029   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 3.5987 - sparse_categorical_accuracy: 0.1723 - val_loss: 2.2843 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - loss: 2.2960 - sparse_categorical_accuracy: 0.1886 - val_loss: 2.2790 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.3048 - sparse_categorical_accuracy: 0.1942 - val_loss: 2.2842 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2752 - sparse_categorical_accuracy: 0.2057\n",
      "[2.2841796875, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd0yzpw8j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd0yzpw8j/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpd0yzpw8j'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_233')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048055587856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055582480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055588240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055584784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050304.751446   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050304.751457   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 25.6921 - sparse_categorical_accuracy: 0.1997 - val_loss: 2.2869 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2869 - sparse_categorical_accuracy: 0.2003 - val_loss: 2.2828 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2877 - sparse_categorical_accuracy: 0.1999 - val_loss: 2.2827 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 911us/step - loss: 2.2750 - sparse_categorical_accuracy: 0.2060\n",
      "[2.282651424407959, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpm5j9m_qf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm5j9m_qf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpm5j9m_qf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_237')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048055587088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138049850775248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138049652096272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138049321638160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050310.551633   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050310.551644   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 4.5454 - sparse_categorical_accuracy: 0.1897 - val_loss: 2.2836 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 2.2833 - sparse_categorical_accuracy: 0.2060 - val_loss: 2.2865 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2929 - sparse_categorical_accuracy: 0.2040 - val_loss: 2.2785 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2716 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2784910202026367, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0o_0vsn7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0o_0vsn7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp0o_0vsn7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_241')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048242745424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048912087504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057110224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057101200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050317.031212   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050317.031223   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 24.6122 - sparse_categorical_accuracy: 0.1695 - val_loss: 2.2817 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2856 - sparse_categorical_accuracy: 0.2062 - val_loss: 2.2797 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2959 - sparse_categorical_accuracy: 0.1963 - val_loss: 2.2888 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2836 - sparse_categorical_accuracy: 0.2060\n",
      "[2.288752317428589, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpugqfmqj1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpugqfmqj1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpugqfmqj1'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_245')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048057110416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057112528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057103312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057113488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050321.624815   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050321.624825   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 6.8786 - sparse_categorical_accuracy: 0.1793 - val_loss: 2.2841 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2806 - sparse_categorical_accuracy: 0.2166 - val_loss: 2.2801 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2847 - sparse_categorical_accuracy: 0.2019 - val_loss: 2.2813 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2737 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2812750339508057, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7e012gq9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7e012gq9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp7e012gq9'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_249')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048037979152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037981264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037990480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037992016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050327.133277   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050327.133287   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 16.9961 - sparse_categorical_accuracy: 0.1749 - val_loss: 2.2808 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2818 - sparse_categorical_accuracy: 0.2078 - val_loss: 2.2824 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2900 - sparse_categorical_accuracy: 0.1983 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 924us/step - loss: 2.2759 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2839484214782715, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcpj9b6by/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcpj9b6by/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpcpj9b6by'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_253')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047705843856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705853072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705849232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705850768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050332.239422   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050332.239433   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 45.1365 - sparse_categorical_accuracy: 0.1927 - val_loss: 2.2801 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2988 - sparse_categorical_accuracy: 0.2056 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2743 - sparse_categorical_accuracy: 0.2018 - val_loss: 2.2858 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - loss: 2.2754 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2858269214630127, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpj77c13rr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj77c13rr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpj77c13rr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_257')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047705845200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705854416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705855568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705844432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050337.745762   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050337.745774   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 9.6544 - sparse_categorical_accuracy: 0.1733 - val_loss: 2.2878 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3050 - sparse_categorical_accuracy: 0.2031 - val_loss: 2.2800 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2878 - sparse_categorical_accuracy: 0.2061 - val_loss: 2.2889 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2828 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2889299392700195, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpp_2m3uwr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp_2m3uwr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpp_2m3uwr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_261')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047699100752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699102864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699094416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699099600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050343.252181   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050343.252193   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - loss: 5692.6968 - sparse_categorical_accuracy: 0.1671 - val_loss: 2.2797 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2950 - sparse_categorical_accuracy: 0.1956 - val_loss: 2.2833 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2913 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.2809 - val_sparse_categorical_accuracy: 0.2038\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 770us/step - loss: 2.2739 - sparse_categorical_accuracy: 0.2059\n",
      "[2.2809133529663086, 0.20383426547050476]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyr5h1uoc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyr5h1uoc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpyr5h1uoc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_265')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047699103440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699103248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699098256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434593808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050348.481951   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050348.481963   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 1763.9943 - sparse_categorical_accuracy: 0.1581 - val_loss: 2.2841 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3008 - sparse_categorical_accuracy: 0.1990 - val_loss: 2.2793 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2876 - sparse_categorical_accuracy: 0.2076 - val_loss: 2.2808 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 829us/step - loss: 2.2738 - sparse_categorical_accuracy: 0.2060\n",
      "[2.280822992324829, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpv3f04yyd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv3f04yyd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpv3f04yyd'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_269')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047434597840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434591888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434601296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434597072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050353.784578   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050353.784589   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 3.8252 - sparse_categorical_accuracy: 0.1936 - val_loss: 2.2816 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2750 - sparse_categorical_accuracy: 0.2019 - val_loss: 2.2832 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 2.2899 - sparse_categorical_accuracy: 0.2080 - val_loss: 2.2866 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 877us/step - loss: 2.2798 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2865545749664307, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_jekpze7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_jekpze7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp_jekpze7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_273')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047434596880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434601488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434604368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302378192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050359.264669   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050359.264680   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 6.7070 - sparse_categorical_accuracy: 0.1598 - val_loss: 2.2856 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2923 - sparse_categorical_accuracy: 0.2023 - val_loss: 2.2848 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.3013 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.2832 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2748 - sparse_categorical_accuracy: 0.2060\n",
      "[2.28324556350708, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzljf5x1n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzljf5x1n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpzljf5x1n'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_277')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047302372624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302383760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302385104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302375312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050364.353289   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050364.353303   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 28.6455 - sparse_categorical_accuracy: 0.1994 - val_loss: 2.2796 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2942 - sparse_categorical_accuracy: 0.1978 - val_loss: 2.2831 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2918 - sparse_categorical_accuracy: 0.2069 - val_loss: 2.2804 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2740 - sparse_categorical_accuracy: 0.2060\n",
      "[2.280442953109741, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_r4apmw6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_r4apmw6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp_r4apmw6'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_281')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047101280016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101286544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101282512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101277712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050370.122715   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050370.122725   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 2613.8911 - sparse_categorical_accuracy: 0.1603 - val_loss: 2.3449 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3888 - sparse_categorical_accuracy: 0.1997 - val_loss: 2.2884 - val_sparse_categorical_accuracy: 0.2040\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2946 - sparse_categorical_accuracy: 0.2068 - val_loss: 2.2825 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2746 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2825281620025635, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpomd9xhok/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpomd9xhok/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpomd9xhok'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_285')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047434603984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434588432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434594000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434593616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050374.996084   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050374.996095   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 169.4732 - sparse_categorical_accuracy: 0.1862 - val_loss: 2.2909 - val_sparse_categorical_accuracy: 0.2027\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2730 - sparse_categorical_accuracy: 0.2120 - val_loss: 2.2915 - val_sparse_categorical_accuracy: 0.2025\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2773 - sparse_categorical_accuracy: 0.1921 - val_loss: 2.2937 - val_sparse_categorical_accuracy: 0.2031\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2863 - sparse_categorical_accuracy: 0.2059\n",
      "[2.2937302589416504, 0.20312128961086273]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpawugcfk2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpawugcfk2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpawugcfk2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_289')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047699092304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699095184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699092112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699107088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050380.735809   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050380.735820   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 14.8088 - sparse_categorical_accuracy: 0.1651 - val_loss: 2.2808 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3162 - sparse_categorical_accuracy: 0.1948 - val_loss: 2.2817 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2743 - sparse_categorical_accuracy: 0.1964 - val_loss: 2.2852 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937us/step - loss: 2.2777 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2851619720458984, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp87gogvf4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp87gogvf4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp87gogvf4'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_293')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047699100944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699094608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048077613200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048077612048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050386.486890   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050386.486901   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 253.8609 - sparse_categorical_accuracy: 0.2003 - val_loss: 2.2861 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2797 - sparse_categorical_accuracy: 0.2072 - val_loss: 2.2812 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2892 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.2857 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2805 - sparse_categorical_accuracy: 0.2060\n",
      "[2.285698175430298, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpo5aw0bmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo5aw0bmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpo5aw0bmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_297')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048055576912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055584208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055581520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055586704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050392.196489   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050392.196499   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 4.8466 - sparse_categorical_accuracy: 0.1688 - val_loss: 2.2858 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2763 - sparse_categorical_accuracy: 0.2095 - val_loss: 2.2849 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2997 - sparse_categorical_accuracy: 0.2069 - val_loss: 2.2815 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2730 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2814972400665283, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpow8tfo00/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpow8tfo00/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpow8tfo00'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_301')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048055335952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055336912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055340560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055333072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050397.524113   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050397.524126   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 7610.9614 - sparse_categorical_accuracy: 0.1509 - val_loss: 2.2819 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2894 - sparse_categorical_accuracy: 0.2042 - val_loss: 2.2797 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2905 - sparse_categorical_accuracy: 0.1810 - val_loss: 2.2879 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2802 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2878925800323486, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwyhvfs2k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwyhvfs2k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpwyhvfs2k'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_305')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048050214672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048050202192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048050213136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048046036944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050402.304646   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050402.304659   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 73.5847 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.2806 - val_sparse_categorical_accuracy: 0.2042\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2697 - sparse_categorical_accuracy: 0.2133 - val_loss: 2.3058 - val_sparse_categorical_accuracy: 0.2030\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2832 - sparse_categorical_accuracy: 0.2283 - val_loss: 2.3531 - val_sparse_categorical_accuracy: 0.2013\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 963us/step - loss: 2.3640 - sparse_categorical_accuracy: 0.2033\n",
      "[2.353102445602417, 0.20129922032356262]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpu6l46qf8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu6l46qf8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpu6l46qf8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_309')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048037983376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037988176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037983760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037978384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050407.159148   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050407.159159   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 5.0901 - sparse_categorical_accuracy: 0.1949 - val_loss: 2.2897 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2974 - sparse_categorical_accuracy: 0.2057 - val_loss: 2.2845 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2885 - sparse_categorical_accuracy: 0.2083 - val_loss: 2.2828 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2764 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2827608585357666, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpm0ofjdmd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm0ofjdmd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpm0ofjdmd'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_313')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047302383376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302378000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302372048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302376656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050411.884947   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050411.884959   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 669.8289 - sparse_categorical_accuracy: 0.1803 - val_loss: 2.2799 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2915 - sparse_categorical_accuracy: 0.2101 - val_loss: 2.2828 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2853 - sparse_categorical_accuracy: 0.2111 - val_loss: 2.2816 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2721 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2815935611724854, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp47jisrsi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp47jisrsi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp47jisrsi'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_317')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047101272528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101282128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101273872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101284624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050417.605079   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050417.605090   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 1088.6278 - sparse_categorical_accuracy: 0.2032 - val_loss: 2.2838 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2814 - sparse_categorical_accuracy: 0.2063 - val_loss: 2.2801 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2914 - sparse_categorical_accuracy: 0.2015 - val_loss: 2.2763 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2679 - sparse_categorical_accuracy: 0.2060\n",
      "[2.276315212249756, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5tgonxx_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5tgonxx_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp5tgonxx_'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_321')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046900268560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900265680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900268944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900260880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050423.196699   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050423.196710   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 10030.8232 - sparse_categorical_accuracy: 0.1629 - val_loss: 2.2864 - val_sparse_categorical_accuracy: 0.2036\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2806 - sparse_categorical_accuracy: 0.2082 - val_loss: 2.2834 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2775 - sparse_categorical_accuracy: 0.2109 - val_loss: 2.2948 - val_sparse_categorical_accuracy: 0.2033\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2842 - sparse_categorical_accuracy: 0.2052\n",
      "[2.294773578643799, 0.20327973365783691]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps1dfye71/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps1dfye71/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmps1dfye71'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_325')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046900260496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900271440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900268368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900261264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050428.067698   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050428.067708   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 46.3508 - sparse_categorical_accuracy: 0.1599 - val_loss: 2.2812 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2929 - sparse_categorical_accuracy: 0.2062 - val_loss: 2.2901 - val_sparse_categorical_accuracy: 0.2034\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2840 - sparse_categorical_accuracy: 0.2113 - val_loss: 2.2852 - val_sparse_categorical_accuracy: 0.2037\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2791 - sparse_categorical_accuracy: 0.2054\n",
      "[2.2851686477661133, 0.20367583632469177]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmph762xxms/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph762xxms/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmph762xxms'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_329')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046895526096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895534544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895536464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895534736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050433.389872   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050433.389883   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 11.5095 - sparse_categorical_accuracy: 0.1641 - val_loss: 2.2808 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2919 - sparse_categorical_accuracy: 0.1966 - val_loss: 2.2858 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2890 - sparse_categorical_accuracy: 0.1972 - val_loss: 2.2803 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2729 - sparse_categorical_accuracy: 0.2060\n",
      "[2.280319929122925, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4tbwq5xi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4tbwq5xi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp4tbwq5xi'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_333')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046895534160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895536272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895536656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697387408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050439.381466   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050439.381478   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 379.1075 - sparse_categorical_accuracy: 0.1919 - val_loss: 2.2887 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2979 - sparse_categorical_accuracy: 0.1906 - val_loss: 2.2848 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2992 - sparse_categorical_accuracy: 0.1919 - val_loss: 2.2793 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2738 - sparse_categorical_accuracy: 0.2060\n",
      "[2.279268741607666, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe_4eanvr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe_4eanvr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpe_4eanvr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_337')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046697376080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697376272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697386832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697376464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050444.471861   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050444.471871   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 3221.3132 - sparse_categorical_accuracy: 0.1989 - val_loss: 2.2782 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2927 - sparse_categorical_accuracy: 0.2044 - val_loss: 2.2810 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2852 - sparse_categorical_accuracy: 0.2078 - val_loss: 2.2844 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 990us/step - loss: 2.2801 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2844078540802, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbilo79h9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbilo79h9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpbilo79h9'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_341')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046697384528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697389712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497308496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497302928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050449.690315   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050449.690327   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - loss: 3526.4539 - sparse_categorical_accuracy: 0.1485 - val_loss: 2.5221 - val_sparse_categorical_accuracy: 0.2019\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 2.4662 - sparse_categorical_accuracy: 0.2043 - val_loss: 2.3466 - val_sparse_categorical_accuracy: 0.2029\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3296 - sparse_categorical_accuracy: 0.1956 - val_loss: 2.3035 - val_sparse_categorical_accuracy: 0.2030\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.3004 - sparse_categorical_accuracy: 0.2043\n",
      "[2.303528070449829, 0.20296284556388855]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2_djywe5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2_djywe5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp2_djywe5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_345')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046497297744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497307344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497306576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497308304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050454.920550   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050454.920562   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 209.2372 - sparse_categorical_accuracy: 0.1760 - val_loss: 2.2847 - val_sparse_categorical_accuracy: 0.2044\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2935 - sparse_categorical_accuracy: 0.2011 - val_loss: 2.2964 - val_sparse_categorical_accuracy: 0.2042\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2634 - sparse_categorical_accuracy: 0.2012 - val_loss: 2.2989 - val_sparse_categorical_accuracy: 0.2038\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2878 - sparse_categorical_accuracy: 0.2062\n",
      "[2.2988626956939697, 0.20383426547050476]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyu0rtjz8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyu0rtjz8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpyu0rtjz8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_349')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046497299856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497296016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497295632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046497305040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050460.507021   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050460.507032   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 473.2087 - sparse_categorical_accuracy: 0.1666 - val_loss: 2.2795 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2832 - sparse_categorical_accuracy: 0.2030 - val_loss: 2.2849 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2964 - sparse_categorical_accuracy: 0.2011 - val_loss: 2.2773 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2694 - sparse_categorical_accuracy: 0.2060\n",
      "[2.277298927307129, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmporwy96i4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmporwy96i4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmporwy96i4'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_353')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046895536848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895529744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895538000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046895533968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050465.484142   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050465.484154   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 2002.0359 - sparse_categorical_accuracy: 0.1880 - val_loss: 2.2811 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2935 - sparse_categorical_accuracy: 0.2043 - val_loss: 2.2806 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2795 - sparse_categorical_accuracy: 0.2027 - val_loss: 2.2809 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923us/step - loss: 2.2732 - sparse_categorical_accuracy: 0.2060\n",
      "[2.28092885017395, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4ozg5o_f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4ozg5o_f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp4ozg5o_f'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_357')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046697388944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697379728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046697386448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900259920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050470.489101   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050470.489113   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 647.1557 - sparse_categorical_accuracy: 0.1576 - val_loss: 2.2817 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2784 - sparse_categorical_accuracy: 0.2018 - val_loss: 2.2827 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2974 - sparse_categorical_accuracy: 0.2036 - val_loss: 2.2798 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2728 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2798285484313965, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps87jglw8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps87jglw8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmps87jglw8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_361')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046900265296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900271248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900268176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046900260304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050475.766572   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050475.766583   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - loss: 3335.6362 - sparse_categorical_accuracy: 0.1526 - val_loss: 2.6931 - val_sparse_categorical_accuracy: 0.2027\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3039 - sparse_categorical_accuracy: 0.2034 - val_loss: 2.7079 - val_sparse_categorical_accuracy: 0.2029\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2606 - sparse_categorical_accuracy: 0.2156 - val_loss: 2.7031 - val_sparse_categorical_accuracy: 0.2023\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.4668 - sparse_categorical_accuracy: 0.2045\n",
      "[2.703075885772705, 0.20232908427715302]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp52g2e8ii/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp52g2e8ii/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp52g2e8ii'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_365')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048046023120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048046022928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057104464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048057113296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050480.706357   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050480.706368   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 1043.1451 - sparse_categorical_accuracy: 0.1791 - val_loss: 2.2891 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2844 - sparse_categorical_accuracy: 0.2088 - val_loss: 2.2832 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2868 - sparse_categorical_accuracy: 0.2065 - val_loss: 2.2855 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2785 - sparse_categorical_accuracy: 0.2060\n",
      "[2.285492181777954, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpenycm077/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpenycm077/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpenycm077'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_369')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048037992784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138049853029072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048037993552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047705844240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050486.103031   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050486.103046   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 737.8005 - sparse_categorical_accuracy: 0.1924 - val_loss: 2.2882 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2979 - sparse_categorical_accuracy: 0.1995 - val_loss: 2.2792 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2890 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.2831 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2739 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2831010818481445, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7qga8opp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7qga8opp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp7qga8opp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_373')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138048055583248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055580560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138048055586512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047699091920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050491.577038   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050491.577049   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 1942.4869 - sparse_categorical_accuracy: 0.1881 - val_loss: 2.2834 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2891 - sparse_categorical_accuracy: 0.1961 - val_loss: 2.2793 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2853 - sparse_categorical_accuracy: 0.1993 - val_loss: 2.2835 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2783 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2835426330566406, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpok_gjy45/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpok_gjy45/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpok_gjy45'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_377')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047434594576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434592848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047434592464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047302369360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050496.999048   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050496.999059   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 5081.7314 - sparse_categorical_accuracy: 0.1618 - val_loss: 2.2909 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2817 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.2787 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2797 - sparse_categorical_accuracy: 0.2032 - val_loss: 2.2802 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2736 - sparse_categorical_accuracy: 0.2061\n",
      "[2.280228853225708, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3iz91fnl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3iz91fnl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp3iz91fnl'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_381')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138047101282320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101284432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101275984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138047101280208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050502.275081   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050502.275092   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - loss: 19653.7051 - sparse_categorical_accuracy: 0.1628 - val_loss: 2.2865 - val_sparse_categorical_accuracy: 0.2040\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2782 - sparse_categorical_accuracy: 0.2165 - val_loss: 2.2810 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2931 - sparse_categorical_accuracy: 0.2113 - val_loss: 2.2804 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2737 - sparse_categorical_accuracy: 0.2062\n",
      "[2.2804226875305176, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4c06r3qz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4c06r3qz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp4c06r3qz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_385')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046492722576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046492728144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046492728528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046492735440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050507.183203   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050507.183215   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 468.3765 - sparse_categorical_accuracy: 0.1622 - val_loss: 2.2815 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.3062 - sparse_categorical_accuracy: 0.2059 - val_loss: 2.2821 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2955 - sparse_categorical_accuracy: 0.1995 - val_loss: 2.2802 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2723 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2801599502563477, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpn00xu_qr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn00xu_qr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpn00xu_qr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_389')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046492725456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046492724688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046492729104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046117638608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050512.336442   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050512.336453   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - loss: 115.5119 - sparse_categorical_accuracy: 0.1621 - val_loss: 2.2834 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2760 - sparse_categorical_accuracy: 0.2195 - val_loss: 2.2842 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2815 - sparse_categorical_accuracy: 0.2084 - val_loss: 2.2806 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2716 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2806127071380615, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbv0il3qz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbv0il3qz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpbv0il3qz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_393')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046117632080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046117629008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046117627856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046117629776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050518.123329   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050518.123338   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 1291.4519 - sparse_categorical_accuracy: 0.1862 - val_loss: 2.2846 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.3023 - sparse_categorical_accuracy: 0.1944 - val_loss: 2.2782 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2861 - sparse_categorical_accuracy: 0.2004 - val_loss: 2.2864 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2781 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2864363193511963, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz8yitbub/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz8yitbub/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpz8yitbub'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_397')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046117640336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046117636688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046110425040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046110430032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050523.560421   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050523.560432   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 303.5921 - sparse_categorical_accuracy: 0.1899 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2855 - sparse_categorical_accuracy: 0.2123 - val_loss: 2.2805 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2621 - sparse_categorical_accuracy: 0.2056 - val_loss: 2.2873 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 811us/step - loss: 2.2804 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2872812747955322, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjny8ewom/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjny8ewom/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpjny8ewom'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_401')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046110432336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046110426960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046110422928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046110427152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050528.707668   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050528.707679   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 2977.4084 - sparse_categorical_accuracy: 0.1722 - val_loss: 2.2807 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2880 - sparse_categorical_accuracy: 0.2082 - val_loss: 2.2802 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2786 - sparse_categorical_accuracy: 0.2124 - val_loss: 2.2815 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 832us/step - loss: 2.2741 - sparse_categorical_accuracy: 0.2060\n",
      "[2.281459331512451, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpib2g_4n7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpib2g_4n7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpib2g_4n7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_405')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046103788752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103788176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103796432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103794128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050533.463852   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050533.463863   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 912.9898 - sparse_categorical_accuracy: 0.1680 - val_loss: 2.2829 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2863 - sparse_categorical_accuracy: 0.1886 - val_loss: 2.2830 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.2939 - sparse_categorical_accuracy: 0.2132 - val_loss: 2.2811 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 857us/step - loss: 2.2728 - sparse_categorical_accuracy: 0.2060\n",
      "[2.281109571456909, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnx794my1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnx794my1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpnx794my1'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_409')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046103783184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103792400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103792976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046103792592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050539.211460   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050539.211471   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 1258.4258 - sparse_categorical_accuracy: 0.1757 - val_loss: 2.2806 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 2.2826 - sparse_categorical_accuracy: 0.1915 - val_loss: 2.2793 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2839 - sparse_categorical_accuracy: 0.2080 - val_loss: 2.2777 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.2691 - sparse_categorical_accuracy: 0.2060\n",
      "[2.277721881866455, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpo_mrxr9r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo_mrxr9r/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpo_mrxr9r'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_413')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046095286800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046095292560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046095294288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046095291792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050544.532443   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050544.532455   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - loss: 2716.8853 - sparse_categorical_accuracy: 0.1539 - val_loss: 2.2837 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2885 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.2824 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 2.3039 - sparse_categorical_accuracy: 0.1988 - val_loss: 2.2787 - val_sparse_categorical_accuracy: 0.2039\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.2704 - sparse_categorical_accuracy: 0.2060\n",
      "[2.2786946296691895, 0.20391349494457245]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpex37n9sa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpex37n9sa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpex37n9sa'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_417')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046095289104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046095290256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046095287184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046089200848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050550.299306   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050550.299317   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moriogai/.virtualenvs/CVEsp32/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - loss: 2499.7629 - sparse_categorical_accuracy: 0.1857 - val_loss: 2.2780 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 2/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 2.2839 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.2808 - val_sparse_categorical_accuracy: 0.2039\n",
      "Epoch 3/3\n",
      "\u001B[1m170/170\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 2.2796 - sparse_categorical_accuracy: 0.2064 - val_loss: 2.2823 - val_sparse_categorical_accuracy: 0.2038\n",
      "\u001B[1m395/395\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2.2770 - sparse_categorical_accuracy: 0.2059\n",
      "[2.2823257446289062, 0.20383426547050476]\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8b_jtla5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8b_jtla5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp8b_jtla5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32, name='keras_tensor_421')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138046089204496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046089213328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046089211984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138046089215632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732050556.209259   25429 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732050556.209272   25429 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T20:40:26.991379Z",
     "start_time": "2024-11-19T20:40:26.989759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "86e587f801c9c78e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
